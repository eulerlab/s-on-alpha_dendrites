{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from alphacnn.database.encoder_schema import *\n",
    "from alphacnn.database import encoder_utils\n",
    "from alphacnn import paths\n",
    "from alphacnn.utils.data_utils import load_config\n",
    "\n",
    "\n",
    "connect_to_database(\n",
    "    dj_config_file=paths.CONFIG_FILE,\n",
    "    create_tables=False, create_schema=False, schema_name=paths.SCHEMA_PREFIX + 'encoder')\n",
    "encoder_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg_dir = 'database_v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(paths.DATASET_PATH, trg_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCNoiseConfigCore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alphacnn.utils.stimulus_utils import get_stimulus_shape\n",
    "\n",
    "overwrite_all = False\n",
    "skip_all_duplicates = True\n",
    "\n",
    "all_stimulus_config_ids, all_stimulus_config_names = StimulusConfig.fetch('stimulus_config_id', 'stimulus_config_file')\n",
    "all_bc_noise_ids = np.unique(BCNoiseConfigCore.fetch(\"bc_noise_id\"))\n",
    "all_rgc_ids = np.unique(RGCSynapticWeights.fetch('rgc_id'))\n",
    "\n",
    "for stimulus_config_id, stimulus_config_name in zip(all_stimulus_config_ids, all_stimulus_config_names):\n",
    "    for bc_noise_id in all_bc_noise_ids:\n",
    "        bc_noise_name = (BCNoiseConfigCore & dict(bc_noise_id=bc_noise_id)).fetch('bc_noise_name')\n",
    "        assert np.unique(bc_noise_name).size == 1\n",
    "        bc_noise_name = bc_noise_name[0]\n",
    "        \n",
    "        for rgc_id in all_rgc_ids:\n",
    "            rgc_name = (RGCSynapticWeights & dict(rgc_id=rgc_id)).fetch('rgc_name')\n",
    "            assert np.unique(rgc_name).size == 1\n",
    "            rgc_name = rgc_name[0]\n",
    "            \n",
    "            dataset_name = 'dataset_' + stimulus_config_name.replace('.yml', '') + '_' + rgc_name\n",
    "            dataset_name += '_bcns' + bc_noise_name\n",
    "\n",
    "            file_path = os.path.join(paths.DATASET_PATH, trg_dir, dataset_name + '.pkl')\n",
    "\n",
    "            if os.path.isfile(file_path) and skip_all_duplicates:\n",
    "                action = 'skip'\n",
    "            elif os.path.isfile(file_path) and not overwrite_all:\n",
    "                user_input = input(f'Overwrite existing file [y=yes/n=no/s=skip]? {file_path}')    \n",
    "                if user_input == 'y':\n",
    "                    action = 'write'\n",
    "                elif user_input == 's':\n",
    "                    action = 'skip'\n",
    "                else:\n",
    "                    action = 'error'\n",
    "            else:\n",
    "                action = 'write'\n",
    "\n",
    "            dataset_tab = encoder_utils.fetch_dataset(\n",
    "                stimulus_config_ids=[stimulus_config_id], rgc_id=rgc_id, bc_noise_id=bc_noise_id)\n",
    "\n",
    "            dataset_df = dataset_tab.fetch(format='frame').reset_index()\n",
    "\n",
    "            if dataset_df.shape[0] == 0:\n",
    "                print('Zero length, skip:', stimulus_config_name)\n",
    "                continue\n",
    "\n",
    "            stim_conf = (StimulusConfig() & dataset_tab).fetch1('stimulus_dict')\n",
    "\n",
    "            pixel_size_um = stim_conf['stimulus']['pixel_size']\n",
    "\n",
    "            width, height, _ = get_stimulus_shape(\n",
    "                pixel_size=pixel_size_um,\n",
    "                stimulus_size_x=stim_conf['stimulus']['size_x'],\n",
    "                stimulus_size_y=stim_conf['stimulus']['size_y'],\n",
    "            )\n",
    "\n",
    "            dataset_df['pixel_size_um'] = pixel_size_um\n",
    "            dataset_df['video_width'] = width\n",
    "            dataset_df['video_height'] = height\n",
    "\n",
    "            if action == 'write':\n",
    "                print(action, file_path)\n",
    "                dataset_df.to_pickle(file_path)\n",
    "            elif action == 'skip':\n",
    "                print(action, file_path)\n",
    "                continue\n",
    "            else:\n",
    "                raise FileExistsError(file_path)\n",
    "\n",
    "            print('----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
